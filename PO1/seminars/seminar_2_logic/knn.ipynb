{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "при подготовке семинара использованы материалы курса \"Машинное обучения\" от АТП ФИВТ МФТИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных\n",
    "\n",
    "скачайте данные с помощью pd.read_csv по ссылке https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data и уберите заголовок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем данные\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data')\n",
    "\n",
    "# Назначаем имена колонок\n",
    "columns = ('age workclass fnlwgt education educ-num marital-status occupation relationship '\n",
    "           'race sex capital-gain capital-loss  hours-per-week native-country salary')\n",
    "\n",
    "df.columns = columns.split() #этот метод разделит датасет по колонкам как в массиве columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выведите первые 5 записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сформируйте новый датафрейм, состоящий из стоблцов 'age, salary'. Подумайте, как можно визуализировать эту информацию при помощи графиков?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['age', 'salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Соотношение классов **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('salary').count()[['age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перекодировка категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с категориальными признаками может быть устроена по разному.\n",
    "\n",
    "В этой задаче предлагается заменить все уникальные значения таких признаков некоторым числовым значением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Подключаем класс для предобработки данных\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Напишем функцию, которая принимает на вход DataFrame, кодирует числовыми значениями категориальные признаки\n",
    "# и возвращает обновленный DataFrame и сами кодировщики.\n",
    "def number_encode_features(init_df):\n",
    "    result = init_df.copy() # копируем нашу исходную таблицу\n",
    "    encoders = {}\n",
    "    for column in result.columns:\n",
    "        if result.dtypes[column] == np.object: # np.object -- строковый тип / если тип столбца - строка, то нужно его закодировать\n",
    "            encoders[column] = preprocessing.LabelEncoder() # для колонки column создаем кодировщик\n",
    "            result[column] = encoders[column].fit_transform(result[column]) # применяем кодировщик к столбцу и перезаписываем столбец\n",
    "    return result, encoders\n",
    "\n",
    "encoded_data, encoders = number_encode_features(df) # Теперь encoded data содержит закодированные кат. признаки \n",
    "encoded_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, во что переведены категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('marital-status').count()[['age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.groupby('marital-status').count()[['age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('workclass').count()[['age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.groupby('workclass').count()[['age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гистограммы значений\n",
    "постройте графики гистограмм зависимости различных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(19,8))\n",
    "cols = 5\n",
    "rows = np.ceil(float(encoded_data.shape[1]) / cols)\n",
    "for i, column in enumerate(encoded_data.columns):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(column)\n",
    "    encoded_data[column].hist(axes=ax)\n",
    "    plt.xticks(rotation=\"vertical\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица корреляций\n",
    "\n",
    "По тепловой карте можно посмотреть на зависимости между признаками, а также на зависимости между целевой переменной и признаками. \n",
    "\n",
    "Положительная зависимость означает прямую зависимость (чем больше одно, тем меньше другое), отрицательная означает обратное.\n",
    "\n",
    "Значение близкое к нулю не обязательно означает отсутствие зависимости! Это лишь значит, что между признаками нет прямой (линейной) зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тоже крутой модуль, для различной визуализации данных\n",
    "import seaborn as sns\n",
    "\n",
    "plt.subplots(figsize=(10,10))\n",
    "encoded_data, encoders = number_encode_features(df)\n",
    "sns.heatmap(encoded_data.corr(), square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос: **\n",
    "    * Почему не всегда хорошо размечать пропуски аналогично известным значениям атрибутов\n",
    "\n",
    "В данном датасете пропущенные значения обозначены как \" ?\".  Удалим из выборки все объекты с пропусками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим все объекты, в которых содержатся пропуски\n",
    "df = df.dropna()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос: **\n",
    "    * Почему не всегда правильно использовать перекодированные категориальные признаки (на примере kNN)?\n",
    "    \n",
    "** Предобработка данных: **\n",
    "     - разметка целевой переменной\n",
    "     - оставляем только числовые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prc = df.copy()\n",
    "df_prc['salary'] = df['salary'].apply((lambda x: x==' >50K')) # Будем предсказывать 1(True), если зарплата больше 50K, 0(False) иначе\n",
    "df_prc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# числовые признаки\n",
    "df._get_numeric_data().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдём категориальные признаки\n",
    "Categorical_cols = list(set(df.columns)- set(df._get_numeric_data().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_prc[df._get_numeric_data().columns])\n",
    "# y = np.array(df_prc['salary'], dtype='int')\n",
    "y = encoders['salary'].transform(df['salary']) # применяем наши кодировщики к категориальным фичам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "# Масштабирование признаков\n",
    "\n",
    "** Вопрос** \n",
    "* Почему для данного датасета может быть полезно привести все признаки к значениями от 0 до 1, для того чтобы использовать kNN в качестве классификатора? \n",
    "\n",
    "В качестве классификатора используем kNN, признаки: число соседей (*n_neighbors*) и метрика (*metrics*).\n",
    "\n",
    "\n",
    "Подберём оптимальные значения указанных гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция отрисовки графиков\n",
    "\n",
    "def grid_plot(x, y, x_label, title, y_label='roc_auc'):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.grid(True)\n",
    "    plt.plot(x, y, 'go-')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будем использовать модель k ближайших соседей\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметра n_neighbors для KNeighborsClassifier\n",
    "\n",
    "У алгоритма knn есть один гиперпараметр (то значение, которое мы выставляем руками) -- число соседей на основе которых алгоритм принимает решение.\n",
    "\n",
    "Как обсуждалось на лекции, подбор подобных параметров можно осуществлять на основе специальной отложенной (тестовой) выборки, а можно с помощью кросс-валидации. (Вспомните, какие плюсы и минусы имеет каждый из подходов)\n",
    "\n",
    "В данной задаче мы будем использовать кросс-валидацию на 5 фолдах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# В sklearn есть специальный модуль для работы с кросс-валидацией\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Зададим сетку - среди каких значений выбирать наилучший параметр.\n",
    "knn_grid = {'n_neighbors': np.array(np.linspace(2, 100, 10), dtype='int')} # перебираем по параметру <<n_neighbors>>, по сетке заданной np.linspace(2, 100, 10)\n",
    "\n",
    "# Создаем объект кросс-валидации\n",
    "gs = GridSearchCV(knn, knn_grid, cv=5)\n",
    "\n",
    "# Обучаем его\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим график зависимости качества от числа соседей\n",
    "# замечание: результаты обучения хранятся в атрибуте cv_results_ объекта gs\n",
    "\n",
    "grid_plot(knn_grid['n_neighbors'], gs.cv_results_['mean_test_score'], 'n_neighbors', 'KNeighborsClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = {'n_neighbors': np.array(np.linspace(15, 35, 11), dtype='int')}\n",
    "gs = GridSearchCV(knn, knn_grid, cv=10)\n",
    "gs.fit(X, y)\n",
    "\n",
    "# best_params_ содержит в себе лучшие подобранные параметры, best_score_ лучшее качество\n",
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_plot(knn_grid['n_neighbors'], gs.cv_results_['mean_test_score'], 'n_neighbors', 'KNeighborsClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование признаков можно выполнить, например, одним из следующих способов способами:\n",
    " - $x_{new} = \\dfrac{x - \\mu}{\\sigma}$, где $\\mu, \\sigma$ — среднее и стандартное отклонение значения признака по всей выборке (см. функцию [scale](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html))\n",
    " - $x_{new} = \\dfrac{x - x_{min}}{x_{max} - x_{min}}$, где $[x_{min}, x_{max}]$ — минимальный интервал значений признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X_scaled = scale(np.array(X, dtype='float'), with_std=True, with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подборка параметра n_neighbors для KNeighborsClassifier при нормированных признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'n_neighbors': np.array(np.linspace(1, 100, 10), dtype='int')}\n",
    "gs = GridSearchCV(knn, grid, cv=5, n_jobs=5)\n",
    "gs.fit(X_scaled, y)\n",
    "print(gs.best_params_, gs.best_score_)\n",
    "grid_plot(grid['n_neighbors'], gs.cv_results_['mean_test_score'], 'n_neighbors', 'KNeighborsClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'n_neighbors': np.array(np.linspace(55, 75, 21), dtype='int')}\n",
    "gs = GridSearchCV(knn, grid, cv=10, n_jobs=5)\n",
    "gs.fit(X_scaled, y)\n",
    "print(gs.best_params_, gs.best_score_)\n",
    "grid_plot(grid['n_neighbors'], gs.cv_results_['mean_test_score'], 'n_neighbors', 'KNeighborsClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос ** \n",
    " * Увеличилась ли точность классификации после нормировки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Метрики </h1> \n",
    "# Метрики для задачи классификации\n",
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поделим выборку на train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_tain, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем 2 классификаторва \n",
    "- умный kNN\n",
    "- глупый -- DummyClassifier (самый популярный класс)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import dummy\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=29) \n",
    "clf_knn = knn.fit(X_train, y_tain)\n",
    "clf_mp = dummy.DummyClassifier(\"most_frequent\").fit(X_train, y_tain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn = clf_knn.predict(X_test)\n",
    "y_mp = clf_mp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$Accuracy = \\frac{\\sum_{x_i, y_i \\in (X, Y)} I(y(x_i) = y_i)}{|(X, Y)|} = \\frac{num~right~classified~obj}{num~all~obj}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print ('knn =', metrics.accuracy_score(y_test, y_knn), 'mp =', metrics.accuracy_score(y_test, y_mp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопросы **\n",
    "* На самом ли деле kNN выдает настолько плохие предсказания?\n",
    "* Какую использовать метрику точности предсказаний при несбалансированных классах?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conf-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "nn_mtx = metrics.confusion_matrix(y_test, y_knn)\n",
    "\n",
    "font = {'family' : 'Calibri', 'weight' : 'bold', 'size'   :22}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "sns.heatmap(nn_mtx, annot=True, fmt=\"d\", \n",
    "            xticklabels=encoders[\"salary\"].classes_, \n",
    "            yticklabels=encoders[\"salary\"].classes_)\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_mtx = metrics.confusion_matrix(y_test, y_mp)\n",
    "\n",
    "font = {'family' : 'Calibri', 'weight' : 'bold', 'size'   :22}\n",
    "matplotlib.rc('font', **font)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "sns.heatmap(mp_mtx, annot=True, fmt=\"d\", \n",
    "            xticklabels=encoders[\"salary\"].classes_, \n",
    "            yticklabels=encoders[\"salary\"].classes_)\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$Precision = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('knn =', metrics.precision_score(y_test, y_knn), 'mp =', metrics.precision_score(y_test, y_mp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос: **\n",
    "* Приведите пример работы классификатора когда precition большой а классификатор работает плохо?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$Recall = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('knn =', metrics.recall_score(y_test, y_knn), 'mp =', metrics.recall_score(y_test, y_mp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос: ** \n",
    "* Приведите пример работы классификатора когда recall большой а классификатор работает плохо?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что важнее, точность или полнота? Какое среднее выбрать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопросы: ** \n",
    "* Как взвесить Precision и Recall?\n",
    "    - Среднее арифметичиское плохо: (p=0.5, r=0.5) должно быть лучше чем (p=1, r=0), \n",
    "    - Лучше минимум, но при равной точности должен побеждать классфикатор с большей полнотой\n",
    "    - Гармоничиское среднее, сглаженный минимум"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(18, 5), ncols=3)\n",
    "\n",
    "x_, y_ = np.arange(0.01, 1, 0.01), np.arange(0.01, 1, 0.01)\n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "\n",
    "Z = [[0.5*x + 0.5*y  for x in x_] for y in y_]\n",
    "axs[0].contour(X, Y, Z)\n",
    "axs[0].set_title('mean')\n",
    "axs[0].set_xlabel('Presition')\n",
    "axs[0].set_ylabel('Recall')\n",
    "\n",
    "Z = [[min(x, y)  for x in x_] for y in y_]\n",
    "axs[1].contour(X, Y, Z)\n",
    "axs[1].set_title('min')\n",
    "axs[1].set_xlabel('Presition')\n",
    "axs[1].set_ylabel('Recall')\n",
    "\n",
    "\n",
    "Z = [[scipy.stats.hmean([x, y])  for x in x_] for y in y_]\n",
    "axs[2].contour(X, Y, Z)\n",
    "axs[2].set_title('harmonik')\n",
    "axs[2].set_xlabel('Presition')\n",
    "axs[2].set_ylabel('Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('knn =', metrics.f1_score(y_test, y_knn), 'mp =', metrics.f1_score(y_test, y_mp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=29).fit(X_train, y_tain)\n",
    "clf_mp = dummy.DummyClassifier(\"most_frequent\").fit(X_train, y_tain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn = clf_knn.predict(X_test)\n",
    "y_mp = clf_mp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_knn)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "print ('ROC AUC = {0:.4f}'.format(metrics.auc(fpr, tpr)))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=20)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_mp)\n",
    "pylab.figure(figsize=(10, 7))\n",
    "pylab.plot([0, 1], [0, 1], 'k--')\n",
    "pylab.plot(fpr, tpr)\n",
    "print ('ROC AUC = {0:.4f}'.format(metrics.auc(fpr, tpr)))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=20)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос **\n",
    "* Когда AUC большой при плохой работе классификатора?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
