{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ноутбук подготовлен на основе "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(model.vocab.keys(), \n",
    "               key=lambda word: model.vocab[word].count,\n",
    "               reverse=True)[:1000]\n",
    "\n",
    "print(words[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = np.array([model.get_vector(word)\n",
    "               for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация эмбеддингов слов с помощью t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
    "                 width=600, height=400, show=True, **kwargs):\n",
    "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
    "    if isinstance(color, str): color = [color] * len(x)\n",
    "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
    "\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
    "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
    "\n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
    "    if show: pl.show(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# map word vectors onto 2d plane with TSNE. hint: use verbose=100 to see what it's doing.\n",
    "\n",
    "word_tsne = TSNE(n_components=2, verbose=100).fit_transform(word_vectors)\n",
    "\n",
    "word_tsne = (word_tsne - np.average(\n",
    "    word_tsne, axis=0).reshape(1, 2)) / np.var(\n",
    "    word_tsne, axis=0).reshape(1, 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_vectors(word_tsne[:, 0], word_tsne[:, 1], color='green', token=words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простая вопросно-ответная система"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data:\n",
    "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt\n",
    "# alternative download link: https://yadi.sk/i/BPQrUu1NaTduEw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = list(open(\"./quora.txt\"))\n",
    "data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(data[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tok should be a list of lists of tokens for each line in data.\n",
    "\n",
    "data_tok = [tokenizer.tokenize(piece_of_data.lower())\n",
    "           for piece_of_data in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrase_embedding(phrase):\n",
    "    \"\"\"\n",
    "    Convert phrase to a vector by aggregating it's word embeddings. See description above.\n",
    "    \"\"\"\n",
    "    # 1. lowercase phrase\n",
    "    # 2. tokenize phrase\n",
    "    # 3. average word vectors for all words in tokenized phrase\n",
    "    # skip words that are not in model's vocabulary\n",
    "    # if all words are missing from vocabulary, return zeros\n",
    "    \n",
    "    \n",
    "    words = tokenizer.tokenize(phrase.lower())\n",
    "    known_vectors = []\n",
    "    for word in words:\n",
    "        if word in model.vocab:\n",
    "            known_vectors.append(model.get_vector(word))\n",
    "    known_vectors = np.array(known_vectors)\n",
    "    if known_vectors.size != 0: \n",
    "        vector = known_vectors.mean(axis=0)\n",
    "    else:\n",
    "        vector = np.zeros([model.vector_size], dtype='float32')\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's only consider ~5k phrases for a first run.\n",
    "chosen_phrases = data[::len(data) // 1000]\n",
    "\n",
    "# compute vectors for chosen phrases\n",
    "phrase_vectors = np.array([get_phrase_embedding(phrase)\n",
    "                 for phrase in chosen_phrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map vectors into 2d space with pca, tsne or your other method of choice\n",
    "# don't forget to normalize\n",
    "\n",
    "phrase_vectors_2d = TSNE(verbose=1000).fit_transform(phrase_vectors)\n",
    "\n",
    "phrase_vectors_2d = (phrase_vectors_2d - \n",
    "                     np.mean(phrase_vectors_2d, axis=0)) / np.std(phrase_vectors_2d, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_vectors(phrase_vectors_2d[:, 0], phrase_vectors_2d[:, 1],\n",
    "             phrase=[phrase[:50] for phrase in chosen_phrases],\n",
    "             radius=20,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute vector embedding for all lines in data\n",
    "data_vectors = np.array([get_phrase_embedding(l) for l in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "def find_nearest(query, k=10):\n",
    "    \"\"\"\n",
    "    given text line (query), return k most similar lines from data, sorted from most to least similar\n",
    "    similarity should be measured as cosine between query and line embedding vectors\n",
    "    hint: it's okay to use global variables: data and data_vectors. see also: np.argsort\n",
    "    \"\"\"\n",
    "        \n",
    "    query_vector = get_phrase_embedding(query)\n",
    "    \n",
    "    distances = cosine_distances(data_vectors, query_vector[None, :])\n",
    "    \n",
    "    indices = np.argsort(distances[:, 0])[:k]   \n",
    "\n",
    "    return [data[index] \n",
    "            for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = find_nearest(query=\"How do i enter the matrix?\", k=10)\n",
    "\n",
    "print(''.join(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_nearest(query=\"How does Trump?\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_nearest(query=\"Why don't i ask a question myself?\", k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
