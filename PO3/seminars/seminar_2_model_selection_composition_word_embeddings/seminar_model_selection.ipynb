{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор оптимальной модели\n",
    "\n",
    "В этом семинаре мы потренируемся обучению, оценке и валидации моделей, подбору оптимальных гиперпараметров, смешиванию моделей. Вам предлагается решить задачу бинарной классификации, а именно построить алгоритм, определяющий превысит ли средний заработок человека порог $50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки. Загрузим данные, уберём пропущенные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data')\n",
    "# Назначаем имена колонок\n",
    "columns = ('age workclass fnlwgt education educ-num marital-status occupation relationship '\n",
    "           'race sex capital-gain capital-loss  hours-per-week native-country salary')\n",
    "\n",
    "numeric_indices = np.array([0, 2, 4, 10, 11, 12])\n",
    "categorical_indices = np.array([1, 3, 5, 6, 7, 8, 9, 13])\n",
    "\n",
    "df.columns = columns.split() #этот метод разделит датасет по колонкам как в массиве columns\n",
    "\n",
    "df = df.replace('?', np.nan)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['salary'] = df['salary'].apply((lambda x: x==' >50K')) # Будем предсказывать 1(True), если зарплата больше 50K, 0(False) иначе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = df[df.columns[numeric_indices]]\n",
    "\n",
    "categorial_data = df[df.columns[categorical_indices]]\n",
    "dummy_features = pd.get_dummies(categorial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([numeric_data, dummy_features], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь всё готово для обучения алгоритмов. Разбейте данные на train и test в соотношении 4:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = #ВАШ КОД"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-валидация\n",
    "\n",
    "![img](https://lh6.googleusercontent.com/IgkIPN6nKjXJEHnbesY2bDCmGkJjSBqtkkF_yLRWlHX_hmfSQpfTC4tyPF13XQsqy9yrqMW4VIjyov-BjuzQKzf4yfFbrSO6HiMgPq9u_Lh5-h2Sdv9k1Mw5rJIDckKdJZ3IeppZpnI)\n",
    "\n",
    "Вместо того, чтобы отделять валидационную выборку от тренировочной, проверяя построенные модели на ней, будем использовать метод кросс-валидации, реализованный вместе с поиском по сетке в классе sklearn.model_selection.GridSearchCV. Суть метода заключается в том, что мы разбиваем обучающую выборку на n частей (фолдов), обучаем алгоритм на каждых из n-1 фолдов и измеряем качество предсказания на оставшемся фолде, а затем усредняем результаты по всем фолдам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, визуализирующую поиск оптимального гиперпараметра модели по сетке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_draw(X, y, model, param_name, grid, param_scale='ordinary', draw=True):\n",
    "    parameters = {param_name: grid}\n",
    "    \n",
    "    CV_model = GridSearchCV(estimator=model, param_grid=parameters, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    CV_model.fit(X, y)\n",
    "    \n",
    "    means = CV_model.cv_results_['mean_test_score']\n",
    "    error = CV_model.cv_results_['std_test_score']\n",
    "    \n",
    "    if draw:\n",
    "        plt.figure(figsize=(15,8))\n",
    "        plt.title('choose ' + param_name)\n",
    "\n",
    "\n",
    "        if (param_scale == 'log'):\n",
    "            plt.xscale('log')\n",
    "\n",
    "        plt.plot(grid, means, label='mean values of score')\n",
    "\n",
    "        plt.fill_between(grid, means - 2 * error, means + 2 * error, color='green', label='filled area between errors')\n",
    "        plt.legend()\n",
    "        plt.xlabel('parameter')\n",
    "        plt.ylabel('roc_auc')\n",
    "        plt.show()\n",
    "        \n",
    "    return means, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделей K ближайших соседей и решающего дерева найдите оптимальные параметры n_neighbors и max_depth. Для алгоритма KNN достаточно ограничиться числом соседей не более 100 и размером сетки не более 20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [KNeighborsClassifier(), DecisionTreeClassifier()]\n",
    "param_names = ['n_neighbors', 'max_depth']\n",
    "grids = #ВАШ КОД: создайте сетки для перебора\n",
    "param_scales = ['ordinary', 'ordinary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, param_name, grid, param_scale in zip(models, \n",
    "                                                param_names, \n",
    "                                                grids, \n",
    "                                                param_scales):\n",
    "    search_and_draw(X_train, y_train, model, param_name, grid, param_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём параметр n_estimators в алгоритме случайный лес. Известно, что случайный лес не переобучается. Поэтому график качества будет монотонно возрастать. Следовательно, необходимо найти минимальное значение n_estimators, при котором качество не изменяется. \n",
    "Поскольку каждое дерево обучается независимо от остальных, достаточно обучить сразу лес из большого количества деревьев, а затем рассмотреть подмножества нужного размера из исходного множества деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_trees = 200\n",
    "\n",
    "values = np.arange(max_trees) + 1\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "global_scores = []\n",
    "\n",
    "for train_indices, val_indices in kf.split(X_train):\n",
    "    scores = []\n",
    "    \n",
    "    X_train_kf = #ВАШ КОД\n",
    "    y_train_kf = #ВАШ КОД\n",
    "    \n",
    "    X_val_kf = #ВАШ КОД\n",
    "    y_val_kf = #ВАШ КОД\n",
    "    \n",
    "    forest = RandomForestClassifier(n_estimators=max_trees)\n",
    "    \n",
    "    #ВАШ КОД: обучите лес на n-1 фолде\n",
    "    \n",
    "    trees = forest.estimators_\n",
    "    \n",
    "    for number_of_trees in values:\n",
    "        thinned_forest = #ВАШ КОД: определите лес из первых number_of_trees деревьев обученного леса\n",
    "\n",
    "        scores.append(roc_auc_score(y_val_kf, thinned_forest.predict_proba(X_val_kf)[:, 1]))\n",
    "    \n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    global_scores.append(scores)\n",
    "\n",
    "global_scores = np.stack(global_scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cross_val_score = global_scores.mean(axis=0)\n",
    "std_cross_val_score = global_scores.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Quality of random forest')\n",
    "\n",
    "plt.plot(values, mean_cross_val_score, label='mean values')\n",
    "plt.fill_between(values, \n",
    "                 mean_cross_val_score - 2 * std_cross_val_score, \n",
    "                 mean_cross_val_score + 2 * std_cross_val_score, \n",
    "                 color='green', \n",
    "                 label='filled area between errors')\n",
    "plt.legend()\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('roc-auc')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормируем признаки и проделаем тот же эксперимент с алгоритмом ближайших соседей. Посмотрим, изменилось ли качество предсказания. В этот раз будем обучаться только на численных признаках: иначе KNeighborsClassifier будет учиться вечность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#ВАШ КОД: преобразуйте выборки X_train и X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [KNeighborsClassifier(), DecisionTreeClassifier()]\n",
    "param_names = ['n_neighbors', 'max_depth']\n",
    "grids = #ВАШ КОД\n",
    "param_scales = ['ordinary', 'ordinary']\n",
    "\n",
    "for model, param_name, grid, param_scale in zip(models, \n",
    "                                                param_names, \n",
    "                                                grids, \n",
    "                                                param_scales):\n",
    "    search_and_draw(X_train[:, numeric_indices], y_train, model, param_name, grid, param_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведём эксперимент над алгоритмом ближайших соседей для оптимального значения глубины из предыдущего пункта на всех признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАШ КОД"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем выводы. Какой из алгоритмов сработал лучше всего? Выберем его и вычислим итоговое качество на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = #ВАШ КОД: ваша лучшая модель\n",
    "\n",
    "#ВАШ КОД\n",
    "\n",
    "y_predicted = #ВАШ КОД: предскажите вероятности на test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, y_predicted)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(*roc_curve(y_test, y_predicted)[:2], label='test AUC=%.4f' % auc)\n",
    "plt.legend(fontsize='large')\n",
    "plt.plot(np.linspace(0,1,100), np.linspace(0,1,100))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что ещё можно делать:\n",
    "\n",
    "Мы подбирали оптимальный одномерный параметр для алгоритма. Можно также:\n",
    "\n",
    "* Искать по сетке не только численные гиперпараметры, но и категориальные, например, метрику в алгоритме ближайших соседей или критерий ветвления в решающем дереве.\n",
    "\n",
    "* Искать оптимальный параметр по многомерной сетке. Перебрать все возможные варианты здесь не выйдет, потому что на это уйдёт слишком много времени. Зато можно перебирать случайные точки по сетке. Эта процедура называется Grid Random Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стекинг\n",
    "\n",
    "Идея стекинга состоит в том, чтобы обучать разнообразные алгоритмы и использовать их в качестве новых признаков объектов. \n",
    "\n",
    "Чтобы избежать переобучения, необходимо разделить обучающую выборку на n фолдов. Для предсказания ответов на k-ом фолде алгоритм обучается на оставшихся n-1 фолдах и предсказывает ответ на k-ом фолде. Такую схему обучения-предсказания реализует функция sklearn.model_selection.cross_val_predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с тем же самым датасетом, что и ранее. Посмотрим, сумеем ли мы побить результаты случайного леса с помощью стекинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meta_feature(model, X_train, X_test, y_train, cv):\n",
    "    try:\n",
    "        train_answers = cross_val_predict(model, X_train, y_train, cv=cv, method='predict_proba')[:, 1]\n",
    "        model.fit(X_train, y_train)\n",
    "        return train_answers, model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    except Exception:\n",
    "        train_answers = cross_val_predict(model, X_train, y_train, cv=cv, method='predict')[:, 1]\n",
    "        model.fit(X_train, y_train)\n",
    "        return train_answers, model.predict(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = #Список ваших любимых моделей из предыдущих пунктов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features_train = np.zeros((X_train.shape[0], 0))\n",
    "meta_features_test = np.zeros((X_test.shape[0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    train, test = compute_meta_feature(model, X_train, X_test, y_train, 5)\n",
    "    meta_features_train = np.append(meta_features_train, train.reshape((train.size, 1)), axis=1)\n",
    "    meta_features_test = np.append(meta_features_test, test.reshape((test.size, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите итоговую модель, которая будет обучаться на метапризнаках. Обучите её и сравните качество на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = #ВАШ КОД: заведите модель\n",
    "\n",
    "#ВАШ КОД: обучите модель\n",
    "\n",
    "y_predicted = #ВАШ КОД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, y_predicted)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(*roc_curve(y_test, y_predicted)[:2], label='test AUC=%.4f' % auc)\n",
    "plt.legend(fontsize='large')\n",
    "plt.plot(np.linspace(0,1,100), np.linspace(0,1,100))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бустинг\n",
    "\n",
    "Попробуем в пару-тройку строк побить всё то качество, которого мы так усердно добивались."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_model = xgboost.XGBClassifier(n_estimators=500)\n",
    "\n",
    "boosting_model.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = boosting_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, y_predicted)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(*roc_curve(y_test, y_predicted)[:2], label='test AUC=%.4f' % auc)\n",
    "plt.legend(fontsize='large')\n",
    "plt.plot(np.linspace(0,1,100), np.linspace(0,1,100))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ml_shad",
   "language": "python",
   "name": "ml_shad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
